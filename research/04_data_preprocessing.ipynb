{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\artificial intelegnce\\\\study\\\\ML End To End Projects Krish Naik\\\\github\\\\End-To-End_Rice-Classification-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\artificial intelegnce\\\\study\\\\ML End To End Projects Krish Naik\\\\github\\\\End-To-End_Rice-Classification-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ProcessedDataConfig:\n",
    "    root_dir: Path\n",
    "    data_dir:Path\n",
    "    train_dir: Path\n",
    "    processed_train_data_pickle_file: Path\n",
    "    valid_dir: Path\n",
    "    processed_valid_data_pickle_file: Path\n",
    "    test_dir: Path\n",
    "    processed_test_data_pickle_file: Path\n",
    "    params_image_fixed_size: tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RiceClassifier.constants import *\n",
    "from RiceClassifier.utils.common import read_yaml, create_directories\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_processed_data_config(self) -> ProcessedDataConfig:\n",
    "        config = self.config.processed_data\n",
    "        data_dir = os.path.join(self.config.data_ingestion.unzip_dir,'Rice_Images')\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        processed_data_config = ProcessedDataConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_dir=Path(data_dir),\n",
    "            train_dir=Path(config.train_dir),\n",
    "            processed_train_data_pickle_file=Path(config.processed_train_data_pickle_file),\n",
    "            valid_dir=Path(config.valid_dir),\n",
    "            processed_valid_data_pickle_file=Path(config.processed_valid_data_pickle_file),\n",
    "            test_dir=Path(config.test_dir),\n",
    "            processed_test_data_pickle_file=Path(config.processed_test_data_pickle_file),\n",
    "            params_image_fixed_size=self.params.IMAGE_FIXED_SIZE\n",
    "            \n",
    "        )\n",
    "        \n",
    "        return processed_data_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from ensure import ensure_annotations\n",
    "from pathlib import Path\n",
    "from RiceClassifier.logger import logger\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from RiceClassifier.utils.common import save_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" class ProcessedData:\\n    def __init__(self, config: ProcessedDataConfig):\\n        self.config = config\\n    \\n    def get_process_data(self):\\n        df_images, df_labels = self.read_images()\\n        X,y = self.resize_image(df_images,df_labels)\\n        X,y = self.scale_date(X,y)\\n        X_train, y_train, X_val, y_val, X_test, y_test = self.separate_data(X,y)       \\n        \\n        train_dataset_list = [X_train, y_train]\\n        valid_dataset_list = [X_val, y_val]\\n        test_dataset_list = [X_test, y_test]\\n        \\n        \\n        print(self.config.processed_train_data_pickle_file)\\n        print(X_train)\\n        \\n        create_directories([Path(self.config.train_dir)]) \\n        create_directories([Path(self.config.valid_dir)]) \\n        create_directories([Path(self.config.test_dir)]) \\n        \\n        \\n            \\n            \\n        self.save_pickle(train_dataset_list,self.config.processed_train_data_pickle_file)\\n        self.save_pickle(valid_dataset_list,self.config.processed_valid_data_pickle_file)\\n        self.save_pickle(test_dataset_list,self.config.processed_test_data_pickle_file)\\n    \\n    \\n    \\n    def read_images(self):\\n        data_dir = self.config.data_dir # Datasets path\\n        data_dir = Path(data_dir)\\n        \\n        arborio = list(data_dir.glob('Arborio/*'))[:100]\\n        basmati = list(data_dir.glob('Basmati/*'))[:100]\\n        ipsala = list(data_dir.glob('Ipsala/*'))[:100]\\n        jasmine = list(data_dir.glob('Jasmine/*'))[:100]\\n        karacadag = list(data_dir.glob('Karacadag/*'))[:100]\\n                # Contains the images path\\n        df_images = {\\n            'arborio' : arborio,\\n            'basmati' : basmati,\\n            'ipsala' : ipsala,\\n            'jasmine' : jasmine,\\n            'karacadag': karacadag\\n        }\\n\\n        # Contains numerical labels for the categories\\n        df_labels = {\\n            'arborio' : 0,\\n            'basmati' : 1,\\n            'ipsala' : 2,\\n            'jasmine' : 3,\\n            'karacadag': 4\\n        }\\n        return df_images, df_labels\\n    \\n    def resize_image(self,df_images,df_labels):\\n        X, y = [], [] # X = images, y = labels\\n        for label, images in df_images.items():\\n            for image in images:\\n                img = cv2.imread(str(image))\\n                resized_img = cv2.resize(img, (224,224)) # Resizing the images to be able to pass on MobileNetv2 model\\n                X.append(resized_img) \\n                y.append(df_labels[label])\\n        return X,y\\n    \\n    def scale_date(self,X1, y1):\\n        X = np.array(X1)\\n        X = X/255\\n        y = np.array(y1)\\n        return X,y\\n    \\n    def separate_data(self,X, y):\\n        X_train, X_test_val, y_train, y_test_val = train_test_split(X, y)\\n        X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val)\\n        \\n        return X_train, y_train, X_val, y_val, X_test, y_test\\n\\n    \\n    \\n    def save_pickle(self, pickle_file, pickle_path):\\n        pickle_path =Path(pickle_path)\\n        print(pickle_path)\\n        pickle.dump(pickle_file,open(pickle_path,'wb'))\\n        logger.info(f'Pickle file saved at: {pickle_path}')\\n    \\n\\n    def load_pickle(self,pickle_path):\\n        pickle_path = Path(pickle_path)\\n        pickle_file = pickle.load(open(pickle_path,'rb'))\\n        logger.info(f'Pickle file loaded from:{pickle_path}')\\n        return pickle_file\\n    \\n    def get_train_data(self):\\n        return self.load_pickle(self.config.processed_train_data_pickle_file)\\n    \\n    def get_valid_data(self):\\n        return self.load_pickle(self.config.processed_valid_data_pickle_file)\\n    \\n    def get_test_data(self):\\n        return self.load_pickle(self.config.processed_test_data_pickle_file) \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" class ProcessedData:\n",
    "    def __init__(self, config: ProcessedDataConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_process_data(self):\n",
    "        df_images, df_labels = self.read_images()\n",
    "        X,y = self.resize_image(df_images,df_labels)\n",
    "        X,y = self.scale_date(X,y)\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = self.separate_data(X,y)       \n",
    "        \n",
    "        train_dataset_list = [X_train, y_train]\n",
    "        valid_dataset_list = [X_val, y_val]\n",
    "        test_dataset_list = [X_test, y_test]\n",
    "        \n",
    "        \n",
    "        print(self.config.processed_train_data_pickle_file)\n",
    "        print(X_train)\n",
    "        \n",
    "        create_directories([Path(self.config.train_dir)]) \n",
    "        create_directories([Path(self.config.valid_dir)]) \n",
    "        create_directories([Path(self.config.test_dir)]) \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        self.save_pickle(train_dataset_list,self.config.processed_train_data_pickle_file)\n",
    "        self.save_pickle(valid_dataset_list,self.config.processed_valid_data_pickle_file)\n",
    "        self.save_pickle(test_dataset_list,self.config.processed_test_data_pickle_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def read_images(self):\n",
    "        data_dir = self.config.data_dir # Datasets path\n",
    "        data_dir = Path(data_dir)\n",
    "        \n",
    "        arborio = list(data_dir.glob('Arborio/*'))[:100]\n",
    "        basmati = list(data_dir.glob('Basmati/*'))[:100]\n",
    "        ipsala = list(data_dir.glob('Ipsala/*'))[:100]\n",
    "        jasmine = list(data_dir.glob('Jasmine/*'))[:100]\n",
    "        karacadag = list(data_dir.glob('Karacadag/*'))[:100]\n",
    "                # Contains the images path\n",
    "        df_images = {\n",
    "            'arborio' : arborio,\n",
    "            'basmati' : basmati,\n",
    "            'ipsala' : ipsala,\n",
    "            'jasmine' : jasmine,\n",
    "            'karacadag': karacadag\n",
    "        }\n",
    "\n",
    "        # Contains numerical labels for the categories\n",
    "        df_labels = {\n",
    "            'arborio' : 0,\n",
    "            'basmati' : 1,\n",
    "            'ipsala' : 2,\n",
    "            'jasmine' : 3,\n",
    "            'karacadag': 4\n",
    "        }\n",
    "        return df_images, df_labels\n",
    "    \n",
    "    def resize_image(self,df_images,df_labels):\n",
    "        X, y = [], [] # X = images, y = labels\n",
    "        for label, images in df_images.items():\n",
    "            for image in images:\n",
    "                img = cv2.imread(str(image))\n",
    "                resized_img = cv2.resize(img, (224,224)) # Resizing the images to be able to pass on MobileNetv2 model\n",
    "                X.append(resized_img) \n",
    "                y.append(df_labels[label])\n",
    "        return X,y\n",
    "    \n",
    "    def scale_date(self,X1, y1):\n",
    "        X = np.array(X1)\n",
    "        X = X/255\n",
    "        y = np.array(y1)\n",
    "        return X,y\n",
    "    \n",
    "    def separate_data(self,X, y):\n",
    "        X_train, X_test_val, y_train, y_test_val = train_test_split(X, y)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val)\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "    \n",
    "    \n",
    "    def save_pickle(self, pickle_file, pickle_path):\n",
    "        pickle_path =Path(pickle_path)\n",
    "        print(pickle_path)\n",
    "        pickle.dump(pickle_file,open(pickle_path,'wb'))\n",
    "        logger.info(f'Pickle file saved at: {pickle_path}')\n",
    "    \n",
    "\n",
    "    def load_pickle(self,pickle_path):\n",
    "        pickle_path = Path(pickle_path)\n",
    "        pickle_file = pickle.load(open(pickle_path,'rb'))\n",
    "        logger.info(f'Pickle file loaded from:{pickle_path}')\n",
    "        return pickle_file\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        return self.load_pickle(self.config.processed_train_data_pickle_file)\n",
    "    \n",
    "    def get_valid_data(self):\n",
    "        return self.load_pickle(self.config.processed_valid_data_pickle_file)\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.load_pickle(self.config.processed_test_data_pickle_file) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProcessedData:\n",
    "    def __init__(self, config: ProcessedDataConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_process_data(self):\n",
    "        df_images, df_labels = self.read_images()\n",
    "        X, y = self.resize_images(df_images, df_labels)\n",
    "        X, y = self.scale_data(X, y)\n",
    "        train_data, valid_data, test_data = self.split_data(X, y)\n",
    "\n",
    "        self.create_directories()\n",
    "        self.save_pickle(train_data, self.config.processed_train_data_pickle_file)\n",
    "        self.save_pickle(valid_data, self.config.processed_valid_data_pickle_file)\n",
    "        self.save_pickle(test_data, self.config.processed_test_data_pickle_file)\n",
    "    \n",
    "    def read_images(self):\n",
    "        data_dir = Path(self.config.data_dir)\n",
    "        image_paths = {\n",
    "            'arborio': list(data_dir.glob('Arborio/*'))[:100],\n",
    "            'basmati': list(data_dir.glob('Basmati/*'))[:100],\n",
    "            'ipsala': list(data_dir.glob('Ipsala/*'))[:100],\n",
    "            'jasmine': list(data_dir.glob('Jasmine/*'))[:100],\n",
    "            'karacadag': list(data_dir.glob('Karacadag/*'))[:100]\n",
    "        }\n",
    "        label_mapping = {\n",
    "            'arborio': 0,\n",
    "            'basmati': 1,\n",
    "            'ipsala': 2,\n",
    "            'jasmine': 3,\n",
    "            'karacadag': 4\n",
    "        }\n",
    "        return image_paths, label_mapping\n",
    "    \n",
    "    def resize_images(self, image_paths, label_mapping):\n",
    "        X, y = [], []\n",
    "        for label, paths in image_paths.items():\n",
    "            for path in paths:\n",
    "                img = cv2.imread(str(path))\n",
    "                resized_img = cv2.resize(img, (224, 224))\n",
    "                X.append(resized_img)\n",
    "                y.append(label_mapping[label])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    def scale_data(self, X, y):\n",
    "        X_scaled = X / 255\n",
    "        return X_scaled, y\n",
    "    \n",
    "    def split_data(self, X, y):\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "        X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "    \n",
    "    def create_directories(self):\n",
    "        create_directories([Path(self.config.train_dir)]) \n",
    "        create_directories([Path(self.config.valid_dir)]) \n",
    "        create_directories([Path(self.config.test_dir)]) \n",
    "    \n",
    "    def save_pickle(self, data, pickle_path):\n",
    "        with open(pickle_path, \"wb\") as file:\n",
    "            pickle.dump(data, file)\n",
    "            logger.info(f'Pickle file saved at: {pickle_path}')\n",
    "    \n",
    "    def load_pickle(self, pickle_path):\n",
    "        with open(pickle_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "            logger.info(f'Pickle file loaded from: {pickle_path}')\n",
    "        return data\n",
    "    \n",
    "    def get_train_data(self):\n",
    "        return self.load_pickle(self.config.processed_train_data_pickle_file)\n",
    "    \n",
    "    def get_valid_data(self):\n",
    "        return self.load_pickle(self.config.processed_valid_data_pickle_file)\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.load_pickle(self.config.processed_test_data_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-07 21:50:58,968: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-07-07 21:50:58,972: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-07-07 21:50:58,974: INFO: common: created directory at: artifacts]\n",
      "[2023-07-07 21:50:58,975: INFO: common: created directory at: artifacts/processed_data]\n",
      "[2023-07-07 21:51:01,933: INFO: common: created directory at: artifacts\\processed_data\\train]\n",
      "[2023-07-07 21:51:01,934: INFO: common: created directory at: artifacts\\processed_data\\valid]\n",
      "[2023-07-07 21:51:01,963: INFO: common: created directory at: artifacts\\processed_data\\test]\n",
      "[2023-07-07 21:51:06,433: INFO: 2432684885: Pickle file saved at: artifacts\\processed_data\\train\\processed_train_data.pkl]\n",
      "[2023-07-07 21:51:08,331: INFO: 2432684885: Pickle file saved at: artifacts\\processed_data\\valid\\processed_valid_data.pkl]\n",
      "[2023-07-07 21:51:09,392: INFO: 2432684885: Pickle file saved at: artifacts\\processed_data\\test\\processed_test_data.pkl]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config= ConfigurationManager()\n",
    "    processed_data_config = config.get_processed_data_config()\n",
    "    processed_data = ProcessedData(config=processed_data_config)\n",
    "    processed_data.get_process_data()\n",
    "except Exception as e: \n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 21:10:18,946: INFO: 2432684885: Pickle file loaded from: artifacts\\processed_data\\train\\processed_train_data.pkl]\n"
     ]
    }
   ],
   "source": [
    "[X_train,y_train] =processed_data.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 2, 1, 1, 1, 2, 0, 4, 3, 2, 1, 3, 2, 2, 3, 3, 2, 3, 2, 3, 2,\n",
       "       0, 1, 1, 3, 2, 4, 2, 0, 1, 0, 4, 0, 3, 3, 3, 1, 1, 1, 3, 1, 4, 0,\n",
       "       3, 1, 0, 0, 3, 1, 4, 2, 4, 1, 2, 4, 1, 3, 1, 4, 2, 1, 3, 0, 1, 2,\n",
       "       4, 0, 4, 1, 1, 2, 2, 3, 2, 3, 3, 3, 2, 1, 3, 2, 4, 2, 1, 4, 2, 4,\n",
       "       3, 2, 3, 2, 3, 3, 1, 1, 3, 4, 4, 4, 4, 2, 3, 1, 1, 1, 2, 2, 1, 1,\n",
       "       3, 2, 4, 3, 1, 2, 4, 1, 3, 3, 1, 4, 0, 4, 0, 2, 0, 2, 1, 3, 1, 0,\n",
       "       0, 0, 1, 1, 3, 3, 2, 0, 0, 2, 4, 3, 1, 0, 4, 4, 2, 2, 2, 4, 0, 2,\n",
       "       4, 1, 2, 4, 2, 1, 0, 2, 2, 0, 0, 0, 2, 3, 2, 4, 0, 4, 2, 2, 2, 1,\n",
       "       4, 1, 0, 1, 1, 4, 0, 3, 4, 0, 3, 0, 1, 0, 3, 4, 4, 2, 2, 4, 4, 3,\n",
       "       2, 2, 2, 2, 4, 2, 4, 4, 3, 3, 2, 2, 1, 0, 2, 4, 1, 3, 2, 1, 0, 3,\n",
       "       0, 4, 4, 0, 4, 0, 2, 0, 2, 4, 3, 0, 3, 4, 0, 3, 2, 2, 0, 3, 0, 3,\n",
       "       2, 1, 3, 4, 1, 3, 4, 3, 2, 0, 3, 0, 4, 1, 4, 1, 4, 1, 1, 0, 0, 3,\n",
       "       2, 2, 0, 3, 4, 1, 2, 4, 1, 3, 2, 4, 3, 2, 3, 1, 1, 1, 3, 0, 3, 0,\n",
       "       4, 3, 2, 4, 1, 4, 0, 1, 0, 1, 2, 3, 4, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 21:02:34,183: INFO: 1711934621: Pickle file loaded from:artifacts\\processed_data\\valid\\processed_valid_data.pkl]\n"
     ]
    }
   ],
   "source": [
    "[X_val,y_val] =processed_data.get_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 2, 2, 3, 1, 2, 4, 1, 2, 1, 4, 0, 1, 0, 1, 3, 1, 4, 1,\n",
       "       1, 1, 0, 2, 1, 1, 0, 2, 3, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 21:17:25,501: INFO: 2432684885: Pickle file loaded from: artifacts\\processed_data\\test\\processed_test_data.pkl]\n"
     ]
    }
   ],
   "source": [
    "[X_test,y_test] =processed_data.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 4, 1, 2, 3, 0, 1, 0, 4, 4, 4, 4, 3, 1, 1, 0, 4, 2, 2, 4,\n",
       "       2, 3, 0, 4, 3, 0, 2, 4, 4, 3, 0, 3, 0, 3, 0, 0, 4, 2, 4, 0, 2, 0,\n",
       "       3, 2, 3, 4, 0, 1, 4, 1, 3, 4, 2, 2, 0, 4, 4, 0, 1, 0, 3, 4, 3, 0,\n",
       "       4, 1, 3, 1, 1, 2, 4, 0, 1, 0, 4, 2, 2, 4, 3, 0, 0, 0, 3, 0, 3, 4,\n",
       "       4, 2, 2, 2, 4, 1, 1, 1, 0, 3, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b5e9cd93bd7a2cc9261663b8bfd32dffc7f676270c9b15565d63e0944060fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
